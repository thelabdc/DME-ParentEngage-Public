{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data visualization\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import os\n",
    "from functools import reduce\n",
    "from collections import OrderedDict \n",
    "\n",
    "\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "\n",
    "standard_background = theme(panel_background = element_blank(),   \n",
    "       panel_grid_major_y = element_blank(),\n",
    "       axis_text_x = element_text(color = \"black\", hjust = 1, size = 24),\n",
    "       axis_text_y = element_text(color = \"black\", size = 24),\n",
    "       legend_text = element_text(color = 'black', size = 24),\n",
    "       legend_title = element_text(color = 'black', size = 24),\n",
    "       axis_title=element_text(size=24),\n",
    "       strip_text_x = element_text(size = 12),\n",
    "       legend_background = element_blank(),\n",
    "       legend_key = element_blank(),\n",
    "       panel_grid_major = element_blank(), \n",
    "       panel_grid_minor = element_blank(),\n",
    "       axis_ticks=element_blank())\n",
    "\n",
    "control_color = \"#444444\"\n",
    "treatment_color = \"#2B4888\"\n",
    "\n",
    "## cleaner school names\n",
    "schoolmap_msg = {'Anacostia HS': \"Anacostia\", \n",
    "                 'Columbia Heights EC (CHEC)': \"CHEC\",\n",
    "                 'Dunbar HS': 'Dunbar'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_crosswalk = pd.read_csv(\"../data/analysis_data/DCPS Student-Parent Crosswalk.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Aggregate messaging data from term 1 and term 2, for both first semester and second semester schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Term 1 messages for first semester schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Load messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load outgoing \n",
    "msg_data_outgoing = pd.read_csv(\"../data/analysis_data/DCPS_Outbound_Messages_for_DME_Award_Study.csv\") \n",
    "msg_data_outgoing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load incoming messages (parental response)\n",
    "parent_response_df = pd.read_csv(\"../data/analysis_data/DCPS_Messages_Incoming_from_Parents.csv\")\n",
    "\n",
    "\n",
    "# for some reason the date/time columns were not named that way\n",
    "parent_response_df.rename(columns = {'to_char': 'date',\n",
    "                                     'to_char.1': 'time'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Prepare messages for concatenating the outgoing and the incoming parent messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_cols = list(set(msg_data_outgoing.columns).intersection(parent_response_df.columns))\n",
    "outgoing_notinc = list(set(msg_data_outgoing.columns).difference(parent_response_df.columns))\n",
    "inc_notoutgoing = list(set(parent_response_df.columns).difference(msg_data_outgoing.columns))\n",
    "\n",
    "same_cols\n",
    "outgoing_notinc\n",
    "inc_notoutgoing\n",
    "\n",
    "## dtypes also appear to be similar (eg not yet datetime format, so rowbind)\n",
    "msg_data_outgoing['broad_type'] = \"school_sent\"\n",
    "parent_response_df['broad_type'] = \"parent_sent\"\n",
    "\n",
    "# file source\n",
    "msg_data_outgoing['file_source'] = 'first_sem_schools_outgoing_term1_msgs'\n",
    "parent_response_df['file_source'] = 'first_sem_schools_incoming_term1_msgs'\n",
    "\n",
    "msg_data_init = pd.concat([msg_data_outgoing,\n",
    "                     parent_response_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_data_outgoing.shape[0] + parent_response_df.shape[0]\n",
    "msg_data_init.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. Clean up messages for blanks and invalid messages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove blank_msgs\n",
    "msg_data_rm_blank = msg_data_init[~msg_data_init.content.isna()].copy()\n",
    "msg_data_rm_blank.shape\n",
    "\n",
    "\n",
    "# We know that this one particular chain is between a student and a school admin, which we do not want \n",
    "# in our sample. Remove!\n",
    "\n",
    "msg_data_rm_blank_student = \\\n",
    "    msg_data_rm_blank.loc[~((msg_data_rm_blank['Student ID'] == os.environ['MESSAGE_IDEXCLUDE'] &\n",
    "                         (msg_data_rm_blank.relationship == 'Unspecified')), ].copy()\n",
    "msg_data_rm_blank_student.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4. Clean up dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term 1 outgoing and incoming messages are day-first\n",
    "msg_data_rm_blank_student['date_dt'] = pd.to_datetime(msg_data_rm_blank_student.date, \n",
    "                                                      dayfirst = True, \n",
    "                                                      errors = 'coerce')\n",
    "\n",
    "msg_data_rm_blank_student.sample(n = 5)[['date', 'date_dt']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Term 2 Messages for First Semester Schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Load messaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term 2 outgoing messaging data for first semester schools\n",
    "term2_remain_outgoing_init = pd.read_excel('../data/analysis_data/DME Messages Term 2 DCPS Pilot Schools Term 1.xlsx',\n",
    "                                          sheet_name=\"Sent Messages\")\n",
    "term2_remain_outgoing_init.shape\n",
    "\n",
    "# Parental response\n",
    "term2_remain_incoming_init = pd.read_excel('../data/analysis_data/DME Messages Term 2 DCPS Pilot Schools Term 1.xlsx',\n",
    "                                          sheet_name=\"Replies\")\n",
    "term2_remain_incoming_init.shape\n",
    "\n",
    "\n",
    "# file source\n",
    "term2_remain_outgoing_init['file_source'] = 'first_sem_schools_outgoing_term2_msgs'\n",
    "term2_remain_incoming_init['file_source'] = 'first_sem_schools_incoming_term2_msgs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Clean up columns in both incoming and outgoing messages for concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term2_remain_outgoing_init.info()\n",
    "\n",
    "term2_remain_incoming_init.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which columns don't line up?\n",
    "same_cols = list(set(term2_remain_outgoing_init.columns).intersection(term2_remain_incoming_init.columns))\n",
    "outgoing_notinc = list(set(term2_remain_outgoing_init.columns).difference(term2_remain_incoming_init.columns))\n",
    "inc_notoutgoing = list(set(term2_remain_incoming_init.columns).difference(term2_remain_outgoing_init.columns))\n",
    "\n",
    "print(\"Same columns:\")\n",
    "same_cols\n",
    "\n",
    "print(\"Cols in outgoing but not incoming:\")\n",
    "outgoing_notinc\n",
    "\n",
    "print(\"Cols in incoming but not outgoing:\")\n",
    "inc_notoutgoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like the identifier column in incoming messages is referring to SIS ID\n",
    "term2_remain_incoming_init[term2_remain_incoming_init.identifier.isin(id_crosswalk.SIS_ID)].shape\n",
    "\n",
    "# Outgoing messages: studentdistrictid = SIS_ID \n",
    "term2_remain_outgoing_init[term2_remain_outgoing_init.studentdistrictid.isin(id_crosswalk.SIS_ID)].shape\n",
    "\n",
    "# Not sure what studentinternal ID is \n",
    "term2_remain_outgoing_init[term2_remain_outgoing_init.studentinternalid.isin(id_crosswalk.STATE_ID)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns \n",
    "# studentdistrictid = SIS_ID \n",
    "\n",
    "# For parent messages\n",
    "term2_remain_incoming_init.rename(columns = {'to_char': 'date',\n",
    "                                             'to_char.1': 'time', \n",
    "                                             'identifier': 'Student ID'}, \n",
    "                                  inplace = True)\n",
    "\n",
    "# For outgoing teacher messages\n",
    "term2_remain_outgoing_init.rename(columns = {'studentdistrictid': 'Student ID', \n",
    "                                             'date2': 'date' },\n",
    "                                  inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "# Remove columns \n",
    "# date2 is the same as date1, just with day first - i'm keeping this column and \n",
    "# removing date1 since the other data are day first as well \n",
    "\n",
    "# we don't know what the id or the studentinternalid columns are; they didn't exist in the first send\n",
    "\n",
    "term2_remain_outgoing_init.drop(columns=['date1', \n",
    "                                         'id', \n",
    "                                         'studentinternalid'], \n",
    "                                axis=1, \n",
    "                                inplace = True)\n",
    "term2_remain_outgoing_init.shape\n",
    "\n",
    "term2_remain_incoming_init.drop(columns=['id', 'sis_id'], axis = 1, inplace = True)\n",
    "term2_remain_incoming_init.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_cols = list(set(term2_remain_outgoing_init.columns).intersection(term2_remain_incoming_init.columns))\n",
    "\n",
    "len(same_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add broad_type column that was included in the original msging data\n",
    "term2_remain_outgoing_init['broad_type'] = \"school_sent\"\n",
    "term2_remain_incoming_init['broad_type'] = \"parent_sent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with blank messages\n",
    "\n",
    "# Filter out messages that are empty\n",
    "print('N outgoing messages w empty content:', \n",
    "       term2_remain_outgoing_init[term2_remain_outgoing_init.content.isna()].shape[0])\n",
    "\n",
    "term2_remain_outgoing = term2_remain_outgoing_init[~term2_remain_outgoing_init.content.isna()].copy()\n",
    "print('N messages remaining', term2_remain_outgoing.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "print('N incoming messages w empty content:', \n",
    "      term2_remain_incoming_init[term2_remain_incoming_init.content.isna()].shape[0])\n",
    "term2_remain_incoming = term2_remain_incoming_init[~term2_remain_incoming_init.content.isna()].copy()\n",
    "print('N messages remaining', term2_remain_incoming.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. Concatenate outgoing and incoming term 2 messages for first semester schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat messages\n",
    "term2_remain_msg_data = pd.concat([term2_remain_outgoing,\n",
    "                                   term2_remain_incoming])\n",
    "term2_remain_msg_data.shape\n",
    "\n",
    "\n",
    "term2_remain_outgoing.shape[0] + term2_remain_incoming.shape[0] == term2_remain_msg_data.shape[0]\n",
    "\n",
    "# remove sis_id\n",
    "term2_remain_msg_data.drop(columns = ['sis_id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4. Clean up dates – they are month first this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term 1 outgoing and incoming messages are month first\n",
    "term2_remain_msg_data['date_dt'] = pd.to_datetime(term2_remain_msg_data.date, \n",
    "                                                      dayfirst = False)\n",
    "\n",
    "term2_remain_msg_data.sample(n = 5)[['date', 'date_dt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term2_remain_msg_data[['date', 'date_dt']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(term2_remain_msg_data.date_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5. Check N columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have the same columns as the \n",
    "same_cols = list(set(msg_data_rm_blank_student.columns).intersection(term2_remain_msg_data.columns))\n",
    "\n",
    "len(same_cols)\n",
    "len(msg_data_rm_blank_student.columns)\n",
    "len(term2_remain_msg_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Term 2 Messages for Second Semester Schools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in term 2 data; these are the second semester schools\n",
    "term2_init = pd.read_excel(\"../data/analysis_data/Term 2 Messaging Data DME Award.xlsx\") \n",
    "term2_init.shape \n",
    "\n",
    "same_cols = list(set(term2_init.columns).intersection(term2_remain_msg_data.columns))\n",
    "len(same_cols)\n",
    "\n",
    "print(\"Same N cols as term 2 schools?\", len(same_cols)==term2_remain_msg_data.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term2_init.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2. Clean up columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that there is some weird shifting of columns going on\n",
    "\n",
    "# For those where the \"Unnamed: 19\" column is empty, the text msgs are in the correct column\n",
    "term2_correct_content = term2_init[term2_init['Unnamed: 19'].isna()].copy()\n",
    "\n",
    "# Text messages in the wrong column\n",
    "term2_incorrect_content = term2_init[~term2_init['Unnamed: 19'].isna()].copy()\n",
    "\n",
    "term2_correct_content.shape[0] + term2_incorrect_content.shape[0] == term2_init.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct\n",
    "term2_correct_content.shape\n",
    "term2_correct_content.name.unique()\n",
    "#term2_correct_content.head()\n",
    "\n",
    "# Incorrect\n",
    "term2_incorrect_content.shape\n",
    "term2_incorrect_content.name.unique()\n",
    "#term2_incorrect_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column name for the bad column\n",
    "\n",
    "\n",
    "# Get index of the student name column\n",
    "x = term2_incorrect_content.columns.get_loc('student_name')\n",
    "\n",
    "# Get the names of the columns beginning 'student_name' and after \n",
    "colnames = list(term2_incorrect_content.columns[x:])\n",
    "\n",
    "# Inert column name at beginning\n",
    "colnames.insert(0, 'bad_column')\n",
    "\n",
    "# Remove the last column from the list ( the \"Unnamed: 19\" one)\n",
    "colnames.pop(-1)\n",
    "\n",
    "# Create list of new column names\n",
    "new_colnames = list(term2_incorrect_content.columns[:x]) + colnames\n",
    "new_colnames\n",
    "\n",
    "\n",
    "# Replace column names if N cols match\n",
    "if len(new_colnames) == term2_incorrect_content.shape[1]:\n",
    "    term2_incorrect_content.columns = new_colnames\n",
    "    \n",
    "#Check\n",
    "# term2_incorrect_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To send to teachertext for verification\n",
    "term2_incorrect_content.to_csv('../data/share_teachertext/teachertext_to_check_bad_column.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3. Before stitching df with bad columns back to the original, clean up the dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For \"correct\" content, it's month first\n",
    "term2_correct_content['date_dt'] = pd.to_datetime(term2_correct_content.to_char, \n",
    "                                                   dayfirst=False, \n",
    "                                                   errors = 'coerce')\n",
    "\n",
    "term2_correct_content.sample(n = 8)[['to_char', 'date_dt']]\n",
    "\n",
    "term2_correct_content['file_source'] = 'second_sem_correct_cols'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For \"incorrect\" content, it's day first\n",
    "# But there are some werid formatting stuff going on, so need to do a more manual edit\n",
    "\n",
    "# Create a fake id column for merging back later on\n",
    "term2_incorrect_content['dt_index'] = ['id_' + str(i) for i in np.arange(1, \n",
    "                                                                         term2_incorrect_content.shape[0]+1)\\\n",
    "                                       .tolist()]\n",
    "\n",
    "# Grab the ones that start with a year\n",
    "manual_date_edit_t2 = term2_incorrect_content[(term2_incorrect_content.to_char.apply(str).str.startswith('2020')|\n",
    "                                              term2_incorrect_content.to_char.apply(str).str.startswith('2019'))]\\\n",
    "                      .copy()\n",
    "\n",
    "manual_date_edit_t2.shape\n",
    "\n",
    "# Apply a strptime – the month comes at the end lol\n",
    "corrected_dates = [pd.to_datetime(datetime.strptime(date, '%Y-%d-%m %H:%M:%S'))\\\n",
    "                   for date in manual_date_edit_t2.to_char.apply(str).to_list()]\n",
    "\n",
    "if len(corrected_dates) == manual_date_edit_t2.shape[0]:\n",
    "    print('Proceed') \n",
    "\n",
    "manual_date_edit_t2['date_dt'] = corrected_dates\n",
    "    \n",
    "# Merge back to dataset\n",
    "term2_incorrect_content_wdates = pd.merge(term2_incorrect_content,\n",
    "                                          manual_date_edit_t2[['dt_index', 'date_dt']], \n",
    "                                          how = 'left', \n",
    "                                          on = 'dt_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For missing dates, do a regular pd dt conversation\n",
    "term2_incorrect_content_wdates['date_dt'] = np.where(term2_incorrect_content_wdates.date_dt.isna(), \n",
    "                                                     pd.to_datetime(term2_incorrect_content.to_char, \n",
    "                                                                    dayfirst=True), \n",
    "                                                     term2_incorrect_content_wdates.date_dt)\n",
    "\n",
    "# Check the max\n",
    "term2_incorrect_content_wdates.date_dt.max()\n",
    "\n",
    "term2_incorrect_content_wdates.sample(n = 8)[['to_char', 'date_dt']]\n",
    "\n",
    "term2_incorrect_content_wdates['file_source'] = 'second_sem_incorrect_cols'\n",
    "\n",
    "term2_incorrect_content_wdates.drop(columns = ['dt_index'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4. Stitch back corrected columns together for term 2 schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns we don't need\n",
    "term2_correct_content.drop(columns=['Unnamed: 19'], inplace = True)\n",
    "term2_incorrect_content_wdates.drop(columns=['bad_column'], inplace = True)\n",
    "\n",
    "# Concat the original correct content, and the corrected incorrect content\n",
    "term2_school_msgs = pd.concat([term2_correct_content, \n",
    "                              term2_incorrect_content_wdates])\n",
    "\n",
    "print('Does the cleaned up version have the same number of rows as the version read in? If True, proceed.', \n",
    "      term2_school_msgs.shape[0] == term2_init.shape[0])\n",
    "\n",
    "# Filter out blank messages\n",
    "term2_school_msgs_rm_blanks = term2_school_msgs[~term2_school_msgs.content.isna()].copy()\n",
    "print('N rows before removing blanks', term2_school_msgs.shape, \n",
    "      '\\nN rows after blanks: ',term2_school_msgs_rm_blanks.shape)\n",
    "\n",
    "term2_school_msgs_rm_blanks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.5. Make columns consistent with the first semester schools' dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term2_school_msgs_rm_blanks.role.unique()\n",
    "\n",
    "# Add the broad type col\n",
    "term2_school_msgs_rm_blanks['broad_type'] = np.where(term2_school_msgs_rm_blanks.role == 'Parent', \n",
    "                                           'parent_sent', \n",
    "                                           'school_sent')\n",
    "\n",
    "# Rename col\n",
    "term2_school_msgs_rm_blanks.rename(columns = {'to_char': 'date',\n",
    "                                             'to_char.1': 'time', \n",
    "                                             'identifier': 'Student ID'}, inplace = True)\n",
    "\n",
    "term2_school_msgs_rm_blanks.drop(columns=['id', 'sis_id'], \n",
    "                                 axis = 1, \n",
    "                                 inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again to see if we have any missing cols\n",
    "same_cols = list(set(term2_school_msgs_rm_blanks.columns).intersection(term2_remain_msg_data.columns))\n",
    "len(same_cols)\n",
    "\n",
    "outgoing_notinc = list(set(term2_school_msgs_rm_blanks.columns).difference(term2_remain_msg_data.columns))\n",
    "inc_notoutgoing = list(set(term2_remain_msg_data.columns).difference(term2_school_msgs_rm_blanks.columns))\n",
    "\n",
    "same_cols\n",
    "outgoing_notinc\n",
    "inc_notoutgoing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term2_all_msgs = pd.concat([term2_school_msgs_rm_blanks, \n",
    "                            term2_remain_msg_data])\n",
    "term2_all_msgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term2_remain_msg_data.date_dt.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Put Term 1 and Term 2 messaging data for all schools together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again to see if we have any missing cols\n",
    "same_cols = list(set(msg_data_rm_blank_student.columns).intersection(term2_all_msgs.columns))\n",
    "len(same_cols)\n",
    "\n",
    "term1_not_term2 = list(set(msg_data_rm_blank_student.columns).difference(term2_all_msgs.columns))\n",
    "term2_not_term1 = list(set(term2_all_msgs.columns).difference(msg_data_rm_blank_student.columns))\n",
    "\n",
    "same_cols\n",
    "term1_not_term2\n",
    "term2_not_term1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put Term 1 and Term 2 messages together\n",
    "msg_data = pd.concat([msg_data_rm_blank_student,\n",
    "                      term2_all_msgs]).drop_duplicates()\n",
    "\n",
    "msg_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean different variables and create basic message features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert dates to the appropriate format\n",
    "\n",
    "msg_data['date_time'] = \\\n",
    " pd.to_datetime(msg_data['date_dt'].astype(str) + ' ' + msg_data.time.astype(str))  \n",
    "\n",
    "msg_data['role'].replace({'Admin': 'Administrator'}, inplace = True)\n",
    "msg_data['relationship'].replace({'parent':'Parent'}, inplace = True)\n",
    "\n",
    "msg_data['content_upper'] = msg_data.content.astype(str).str.upper()\n",
    "msg_data['student_upper'] = msg_data.student_name.astype(str).str.upper()\n",
    "\n",
    "#tokenize student names\n",
    "msg_data['student_tokens'] = msg_data.student_upper.str.split(' ')\n",
    "\n",
    "# Some students can have two first names, e.g. Ann Marie Smith\n",
    "# This should take care of most of the cases\n",
    "\n",
    "#If len of token > 2, concat first 2 tokens, else just take first token\n",
    "msg_data['student_2_name'] = np.where(msg_data.student_tokens.str.len() > 2, \n",
    "                                      msg_data['student_tokens'].apply(lambda x: x[:2]), \n",
    "                                      msg_data['student_tokens'].apply(lambda x: x[:1]))\n",
    "\n",
    "msg_data['student_2_name'] = msg_data['student_2_name'].str.join(' ')\n",
    "\n",
    "## one version of student firstname \n",
    "## is everything before first space (could be weird if multiple names)\n",
    "msg_data['student_firstname_spaceversion']  = msg_data.student_upper.str.split(' ').str[0]\n",
    "name_var = 'student_firstname_spaceversion' # in case we change\n",
    "\n",
    "## last names\n",
    "msg_data['student_last_name'] = msg_data.student_upper.str.split(' ').str[-1]\n",
    "msg_data['receiver_last_name'] = msg_data.receiver_full_name.str.upper().str.split(' ').str[-1]\n",
    "msg_data['sender_lname'] =  msg_data.sender_full_name.str.upper().str.split(' ').str[-1]\n",
    "msg_data['receiver_fullname_upper'] = msg_data.receiver_full_name.str.upper()\n",
    "\n",
    "msg_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Different versions of messages\n",
    "\n",
    "Even though only really relevant for the outgoing messages, applied to both for the purposes of consistency\n",
    "\n",
    "The id part also might flag more stock parent responses (\"Thank you!\") versus more in-depth responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_possessive(name_var):\n",
    "    '''\n",
    "    Fn that takes in a name and returns the \n",
    "    original and possessive form of the name\n",
    "    '''\n",
    "    student_fname = name_var\n",
    "    student_fname_possessive = student_fname + \"'S\"\n",
    "    return student_fname_possessive, student_fname\n",
    "\n",
    "\n",
    "def remove_names_alternate(one_row):\n",
    "    '''\n",
    "    Process a df, by taking the name vars and creating the possessive version.\n",
    "    Checks and removes the two-named version first, then repeats for single names\n",
    "    Ensures that we preserve teachers' names\n",
    "    (This accounts for cases like, \"Jose\" as student fname, and Ms. Joseph as teacher lname)\n",
    "    '''\n",
    "    # create the possessive version of student names, for both single name and 2-name version \n",
    "    two_fname_possessive, two_fname = create_possessive(one_row.loc['student_2_name'])\n",
    "    fname_possessive, fname = create_possessive(one_row.loc['student_firstname_spaceversion'])\n",
    "    \n",
    "    two_names = [two_fname_possessive, two_fname]\n",
    "    names = [fname_possessive, fname]\n",
    "    \n",
    "    sender_lname = one_row.loc['sender_lname']\n",
    "    titles = ['MR.', 'MRS.', 'MS.', 'MR', 'MRS', 'MS', 'SR', 'SRA', 'SR.', 'SRA.'] # add a couple but dk if they're found\n",
    "    list_sender_names = [title +' '+ sender_lname for title in titles]\n",
    "    \n",
    "    # Look to see if sender's lname exists in search\n",
    "    sender_name_search = re.search('|'.join(list_sender_names), one_row['content_upper'])\n",
    "    \n",
    "    # If the sender's last name doesn't exist in the string, then just remove student name \n",
    "    # Otherwise, find the start and end position of the sender's name. \n",
    "    # Remove student names from first half of string until starting position of sender name \n",
    "    # Remove student names from second half of string starting from the last position of sender name \n",
    "    # Concat the 2 halves together (with the sender name added back in)\n",
    "    \n",
    "    if sender_name_search is None: \n",
    "        msg_noname = re.sub(\"|\".join(two_names), '', one_row.loc['content_upper'])\n",
    "        msg_noname = re.sub(\"|\".join(names), '', msg_noname)\n",
    "        \n",
    "    else:\n",
    "        start = sender_name_search.start() #find start position of sender name\n",
    "        end =  sender_name_search.end() #find end position of sender name\n",
    "        \n",
    "        # First part of string, remove names of students with two names first\n",
    "        msg_noname_part1 = re.sub(\"|\".join(two_names), '', one_row.loc['content_upper'][ : start])\n",
    "        msg_noname_part1 = re.sub(\"|\".join(names), '', msg_noname_part1)\n",
    "        \n",
    "        # Second part of string, remove two name first\n",
    "        msg_noname_part2 = re.sub(\"|\".join(two_names), '', one_row.loc['content_upper'][end : ])\n",
    "        msg_noname_part2 = re.sub(\"|\".join(names), '', msg_noname_part2)\n",
    "    \n",
    "        # concat the strings back together \n",
    "        # .group() returns the matched item \n",
    "        msg_noname = msg_noname_part1 + sender_name_search.group() + msg_noname_part2\n",
    "        \n",
    "    # Rm extra whitespace that might exist as a result\n",
    "    msg_noname_removews = re.sub(r'\\s+', ' ', msg_noname)\n",
    "    \n",
    "    return(msg_noname_removews)\n",
    "\n",
    "\n",
    "def create_newids(variable_forid: str, df: pd.DataFrame):\n",
    "    ## first check of exists\n",
    "    new_name = \"id_\" + variable_forid\n",
    "    \n",
    "    if new_name in df.columns:\n",
    "        print(\"Already created; skip\")\n",
    "        return(df)\n",
    "    \n",
    "    else:\n",
    "        print(\"Haven't yet created; create\")\n",
    "        ## subset to that var and dedup\n",
    "        df_dedup = df[[variable_forid]].drop_duplicates()\n",
    "\n",
    "        ## create id col\n",
    "        df_dedup[new_name] = [\"id_\" + str(i) for i in np.arange(1, df_dedup.shape[0]+1).tolist()]\n",
    "\n",
    "        ## left join with original df and return\n",
    "        df_return = pd.merge(df, df_dedup, on = variable_forid, how = \"left\")\n",
    "        \n",
    "        return(df_return)\n",
    "    \n",
    "    \n",
    "def create_newids_wgrouping(variable_forid: str, \n",
    "                            grouping_vars_list: list,\n",
    "                  df: pd.DataFrame):\n",
    "    ''' \n",
    "    Give each unique message a unique ID\n",
    "    '''\n",
    "    ## first check of exists\n",
    "    new_name = \"id_\" + variable_forid + '_wgroup'\n",
    "    \n",
    "    if new_name in df.columns:\n",
    "        print(\"Already created; skip\")\n",
    "        return(df)\n",
    "    \n",
    "    else:\n",
    "        #init list\n",
    "        grouping_vars_list.append(variable_forid)\n",
    "        ## subset to that var and dedup\n",
    "        df_dedup = df[grouping_vars_list].drop_duplicates()\n",
    "\n",
    "        ## create id col\n",
    "        df_dedup[new_name] = [\"id_\" + str(i) for i in np.arange(1, df_dedup.shape[0]+1).tolist()]\n",
    "\n",
    "        ## left join with original df and return\n",
    "        df_return = pd.merge(df, df_dedup, on = grouping_vars_list, how = \"left\")\n",
    "        \n",
    "        return(df_return)\n",
    "    \n",
    "    \n",
    "def remove_receiver_name_withtitle(one_row):\n",
    "    '''\n",
    "    Remove receiver (either parent or teacher) last name from the msg \n",
    "    Removes either name or posessive\n",
    "    '''\n",
    "    \n",
    "    one_message = one_row.loc['content_nostudentname']\n",
    "    receiver_lname = one_row.loc['receiver_last_name']\n",
    "    receiver_fullname = one_row.loc['receiver_fullname_upper']\n",
    "    titles = ['MR.', 'MRS.', 'MS.', 'MR', 'MRS', 'MS', 'SR', 'SRA', 'SR.', 'SRA.']\n",
    "    list_receiver_names = [title +' '+ receiver_lname for title in titles] + [receiver_fullname]\n",
    "    receiver_name_search = re.search('|'.join(list_receiver_names), one_message)\n",
    "    if receiver_name_search is None: \n",
    "        #debugging: print(\"name not found, returning: \" + one_message)\n",
    "        return(one_message)\n",
    "    else:\n",
    "        msg_norecname = re.sub(receiver_name_search.group(), \"\", one_message)\n",
    "        msg_noname_removews = re.sub(r'\\s+', ' ', msg_norecname)\n",
    "        # debugging: print(\"name found, returning: \" + msg_noname_removews)\n",
    "        return(msg_noname_removews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove students' names (using function that preserves teacher names)\n",
    "msg_data['content_nostudentname'] = msg_data.apply(remove_names_alternate, axis = 1)\n",
    "msg_data['content_noreceiverstudentname'] = msg_data.apply(remove_receiver_name_withtitle, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(msg_data.content_nostudentname.unique()) != len(msg_data.content_noreceiverstudentname.unique()):\n",
    "    print(\"did something different to the messages; proceed\")\n",
    "else:\n",
    "    print(\"same n unique; check your code again pls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Give messages a unique ID\n",
    "msg_data['id'] = [\"id_\" + str(i) for i in np.arange(1, msg_data.shape[0]+1).tolist()] #give text messages a fake id\n",
    "\n",
    "\n",
    "## above id is for each message; create new id that creates an id for each set of duplicated messages \n",
    "## (before stud name removal)\n",
    "content_list = ['content_upper','content_nostudentname', 'content_noreceiverstudentname']\n",
    "\n",
    "# round to minutes for goruping\n",
    "msg_data['date_time_minutes'] = msg_data.date_time.dt.floor('Min') \n",
    "\n",
    "for colname in content_list:\n",
    "    # for every content column, \n",
    "    # create a new id (drops duplicate msgs)\n",
    "    msg_data = create_newids(variable_forid=colname,\n",
    "                             df = msg_data)\n",
    "    print('N Unique IDs: id_'+ colname, msg_data['id_' + colname].nunique())\n",
    "    \n",
    "    # for every content column, \n",
    "    # create a new id based on sender and date time in minutes\n",
    "    msg_data = create_newids_wgrouping(variable_forid = colname,\n",
    "                                       grouping_vars_list=[\"sender_full_name\", \"date_time_minutes\"],\n",
    "                                       df = msg_data)\n",
    "    \n",
    "    print('N Unique IDs: id_'+ colname, '_wgroup ', msg_data['id_' + colname + '_wgroup'].nunique(), sep = '')\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for a given message, get count of appearances\n",
    "countappearances_message_removename = \\\n",
    "              pd.DataFrame({'message_id': msg_data.id_content_nostudentname\\\n",
    "                                                    .value_counts().index,\n",
    "                            'count_appearances_message_removename': msg_data.id_content_nostudentname\\\n",
    "                                                    .value_counts()})\n",
    "\n",
    "countappearances_message_withname = pd.DataFrame({'message_id': msg_data.id_content_upper.value_counts().index,\n",
    "                            'count_appearances_message': msg_data.id_content_upper.value_counts()})\n",
    "\n",
    "\n",
    "## left join onto main messaging data\n",
    "msg_data_tomerge = msg_data.copy()\n",
    "\n",
    "msg_data_wcounts = pd.merge(msg_data_tomerge, \n",
    "                            countappearances_message_removename, \n",
    "                            left_on = ['id_content_nostudentname'],\n",
    "                            right_on = ['message_id'], \n",
    "                            how = 'left')\n",
    "\n",
    "msg_data_wcounts_more = pd.merge(msg_data_wcounts, \n",
    "                                 countappearances_message_withname, \n",
    "                                 left_on = ['id_content_upper'],\n",
    "                                 right_on = ['message_id'], \n",
    "                                 how = 'left')\n",
    "msg_data_wcounts_more.drop(['message_id_x', \"message_id_y\"], axis = 1, inplace = True)\n",
    "msg_data_wcounts_more['stock_msg'] = np.where(msg_data_wcounts_more.id_content_nostudentname.duplicated(keep = False),\n",
    "                                           1, 0)\n",
    "\n",
    "## reassign\n",
    "msg_data = msg_data_wcounts_more.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create more basic message-level features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_data['n_tokens_rawmsg'] = msg_data.apply(lambda row: len(nltk.word_tokenize(row['content_upper'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get string length\n",
    "msg_data['rawmsg_len'] = msg_data.content_upper.str.len()\n",
    "msg_data['no_student_len'] = msg_data.content_nostudentname.str.len()\n",
    "msg_data['no_stud_receiver_len'] = msg_data.content_noreceiverstudentname.str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_data['teacher_parent_samelname'] = np.where(msg_data.sender_lname == msg_data.receiver_last_name, 1, 0)\n",
    "print('Breakdown of parents + teachers with same lname')\n",
    "msg_data.teacher_parent_samelname.value_counts()\n",
    "\n",
    "msg_data.rename(columns = {'name': 'school_name'}, inplace = True)\n",
    "name_list = [name_var, 'receiver_last_name', 'student_last_name']\n",
    "var_name_list = ['uses_student_name', 'uses_receiver_name', 'uses_student_lname']\n",
    "for i in range(len(name_list)):\n",
    "    msg_data[var_name_list[i]] = \\\n",
    "        np.where([x[0] in x[1] for x in zip(msg_data[name_list[i]], msg_data['content_upper'])],\n",
    "                 1, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prepare output files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changing to more efficient method\n",
    "msg_data.rename(columns={'Student ID': 'StudentID'}, inplace = True)\n",
    "\n",
    "msg_data['school_merge'] = np.where(msg_data.school_name.str.contains(\"CHEC\"),\n",
    "                                'CHEC',\n",
    "                           np.where(msg_data.school_name.str.contains(\"Anacostia\"),\n",
    "                                'Anacostia', \n",
    "                           np.where(msg_data.school_name.str.contains(\"Dunbar\"),\n",
    "                                 'Dunbar',\n",
    "                           np.where(msg_data.school_name.str.contains(\"Paul\"),\n",
    "                                 'Paul',\n",
    "                           np.where(msg_data.school_name.str.contains(\"Friendship\"),\n",
    "                                 'Friendship',\n",
    "                           'Johnson'))))) \n",
    "\n",
    "# Check if this is done correctly\n",
    "msg_data[['school_name', 'school_merge']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_data.date_dt.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_data[msg_data.date_dt == msg_data.date_dt.max()][['date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Write outputs as pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_data.to_pickle('../data/analysis_data/full_year_msg_data_pickle_MODIFIED_01282021.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
