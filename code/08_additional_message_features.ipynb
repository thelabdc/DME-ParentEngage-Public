{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "1. Create role ids for teachers and parents\n",
    "2. Create text chain ids (i.e., an ID for teacher-parent pair)\n",
    "3. Fix date-time weirdness\n",
    "4. Manual language correction for \"Grasias\"\n",
    "5. Create lead/lag messages to see the replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data visualization\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, date\n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msg_data = pd.read_pickle('../data/analysis_data/msgs_wdem_wtrans_1203.pkl')\n",
    "msg_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create role ids for teachers and parents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. For teachers and administrators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, role ids for teachers and admin (from old script 8)\n",
    "role_id_schoolsent = msg_data.loc[msg_data.broad_type == \"school_sent\",\n",
    "                                 ['sender_full_name', 'role']].drop_duplicates()\n",
    "\n",
    "teacher_id = role_id_schoolsent[role_id_schoolsent.role == 'Teacher'].copy()\n",
    "teacher_id['role_id'] = ['teacher_id_' + str(i) for i in np.arange(1, (len(teacher_id)+1))]\n",
    "admin_id = role_id_schoolsent[role_id_schoolsent.role == 'Administrator'].copy()\n",
    "admin_id['role_id'] = ['admin_id_' + str(i) for i in np.arange(1, (len(admin_id)+1))]\n",
    "\n",
    "# rowbind the teacher and admin ids together\n",
    "role_id_combined = teacher_id.append(admin_id, ignore_index = True)\n",
    "\n",
    "# check duplicates-- see that two classified as both teachers and administrators\n",
    "school_sent_multiple_roles = role_id_combined[role_id_combined.sender_full_name\\\n",
    "                                             .duplicated(keep=False)].copy()\n",
    "#school_sent_multiple_roles\n",
    "\n",
    "# Remove duplicates from our dataset\n",
    "multiple_role_list = school_sent_multiple_roles['sender_full_name'].drop_duplicates().tolist()\n",
    "role_id_combined_tomerge = role_id_combined[~((role_id_combined.sender_full_name.isin(multiple_role_list)) & \n",
    "                                             (role_id_combined.role == 'Teacher'))].copy()\n",
    "\n",
    "role_id_combined.shape\n",
    "role_id_combined_tomerge.shape\n",
    "\n",
    "\n",
    "# in messaging data, reassign the role to be \"Administrator\" \n",
    "# if the sender name is in the multple role list \n",
    "msg_data['role'] = np.where(msg_data.sender_full_name.isin(multiple_role_list), \n",
    "                           'Administrator', \n",
    "                            msg_data.role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. For parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## might want to add school as well?\n",
    "all_sending_parents = msg_data.loc[msg_data.broad_type == \"parent_sent\",\n",
    "                     ['sender_full_name', 'StudentID', 'school_merge']]\\\n",
    "                     .rename(columns = {'sender_full_name': 'parent_full_name'}).drop_duplicates()\n",
    "\n",
    "all_receiving_parents = msg_data.loc[msg_data.broad_type == \"school_sent\",\n",
    "                        ['receiver_full_name', 'StudentID', 'school_merge']]\\\n",
    "                        .rename(columns = {'receiver_full_name': 'parent_full_name'}).drop_duplicates()\n",
    "\n",
    "all_parents_togiveids = pd.concat([all_sending_parents,\n",
    "                                 all_receiving_parents]).drop_duplicates()\n",
    "\n",
    "print(\"There are {} students with {} parent names\".format(len(all_parents_togiveids.StudentID.unique()),\n",
    "                                                    all_parents_togiveids.shape[0]))\n",
    "\n",
    "all_parents_togiveids['role_id'] = ['parent_id_' + str(i) for i in np.arange(1, len(all_parents_togiveids)+1)]\n",
    "\n",
    "#all_parents_togiveids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ids_to_rm = ['teacher_id_100', 'teacher_id_113', 'teacher_id_127', 'teacher_id_142']\n",
    "\n",
    "#role_ids_rm_dupes = role_id_combined_tomerge[~role_id_combined_tomerge.role_id.isin(ids_to_rm)].copy()\n",
    "\n",
    "#Should rm 4\n",
    "#role_id_combined_tomerge.shape[0] - role_ids_rm_dupes.shape[0]==4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Stitch ids back to original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. Start with the school dataset first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs_school_sent = msg_data[msg_data.broad_type == 'school_sent'].copy()\n",
    "msgs_school_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the senders have an assigned role id\n",
    "msgs_school_sent_wrole_id = pd.merge(msgs_school_sent, \n",
    "                                     role_id_combined_tomerge, \n",
    "                                     how = 'left', \n",
    "                                     on = ['sender_full_name', 'role'])\\\n",
    "                            .rename(columns = {'role_id': 'sender_role_id'})\n",
    "\n",
    "# Give the msg receivers their assigned ID\n",
    "msgs_school_sent_wrole_wparent = pd.merge(msgs_school_sent_wrole_id,\n",
    "                                          all_parents_togiveids, how = 'left', \n",
    "                                          left_on=['receiver_full_name', 'school_merge', 'StudentID'],\n",
    "                                          right_on=['parent_full_name', 'school_merge', 'StudentID'])\\\n",
    "                                .rename(columns = {'role_id': 'receiver_role_id'})#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a random one, are they the same?\n",
    "check_names = all_parents_togiveids[all_parents_togiveids.role_id=='parent_id_2153']['parent_full_name'].values == \\\n",
    "              msgs_school_sent_wrole_wparent[msgs_school_sent_wrole_wparent\\\n",
    "                                             .receiver_role_id == 'parent_id_2153']['parent_full_name']\\\n",
    "             .drop_duplicates()\n",
    "\n",
    "if check_names[0]:\n",
    "    msgs_school_sent_wrole_wparent.drop(columns='parent_full_name', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if msgs_school_sent_wrole_wparent.shape[0] == msgs_school_sent.shape[0]:\n",
    "    print('Proceed with parent-sent messages')\n",
    "else: \n",
    "    print('Stop! Something added extra rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2. Then the parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs_parent_sent = msg_data[msg_data.broad_type == 'parent_sent'].drop_duplicates().copy()\n",
    "msgs_parent_sent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Give parent-sent messages a sender id\n",
    "msgs_parent_sent_wsender_id = pd.merge(msgs_parent_sent, \n",
    "                                       all_parents_togiveids, \n",
    "                                       how = 'left',\n",
    "                                       left_on = ['sender_full_name', 'school_merge', 'StudentID'],\n",
    "                                       right_on = ['parent_full_name', 'school_merge', 'StudentID'])\\\n",
    "                              .drop(columns = 'parent_full_name')\\\n",
    "                              .rename(columns = {'role_id': 'sender_role_id'})\n",
    "\n",
    "msgs_parent_sent_wsender_id.shape[0] == msgs_parent_sent.shape[0]\n",
    "\n",
    "\n",
    "#Give receivers their ID\n",
    "\n",
    "msgs_parent_sent_wsender_receiver_id = pd.merge(msgs_parent_sent_wsender_id, \n",
    "                                                role_id_combined_tomerge\\\n",
    "                                                .rename(columns = {'sender_full_name': 'receiver_full_name'})\\\n",
    "                                                .drop(columns = ['role']),\n",
    "                                               how = 'left', \n",
    "                                               on = 'receiver_full_name')\\\n",
    "                                               .rename(columns = {'role_id':'receiver_role_id'})\n",
    "\n",
    "msgs_parent_sent_wsender_receiver_id.shape[0] == msgs_parent_sent.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Rowbind data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs_wrole_id = msgs_school_sent_wrole_wparent\\\n",
    "                .append(msgs_parent_sent_wsender_receiver_id, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msgs_wrole_id.to_pickle('../data/analysis_data/translated_msgs_wrole_ids_1214.pkl')\n",
    "#msgs_wrole_id.to_pickle('../data/analysis_data/translated_msgs_wrole_ids_1221.pkl')\n",
    "\n",
    "if msgs_wrole_id.shape[0] == msg_data.shape[0]:\n",
    "    print('Proceed')\n",
    "else:\n",
    "    print('Something is wrong. Double check')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create text chain ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text chain ids, ensuring that it starts with teh teacher/admin role id\n",
    "\n",
    "msgs_wrole_id['text_chain_ids'] = \\\n",
    "    np.where(msgs_wrole_id.sender_role_id.str.startswith('parent_'), \n",
    "             msgs_wrole_id.receiver_role_id + ':' + msgs_wrole_id.sender_role_id,\n",
    "             msgs_wrole_id.sender_role_id + ':' + msgs_wrole_id.receiver_role_id)\n",
    "\n",
    "msgs_wrole_id[['text_chain_ids']].drop_duplicates().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fix date and time formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct_dates_init = pd.read_pickle('../data/analysis_data/full_year_msg_data_pickle_MODIFIED_01282021.pkl')\n",
    "\n",
    "df_correct_dates = df_correct_dates_init[['id', 'content', 'date_dt', 'file_source']]\\\n",
    "                    .copy().rename(columns = {'date_dt': 'date_dt_corrected'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs_wrole_id.shape\n",
    "df_correct_dates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs_wrole_id = pd.merge(msgs_wrole_id, \n",
    "                                     df_correct_dates, \n",
    "                                     how = 'left', \n",
    "                                     on = ['id', 'content'], \n",
    "                                     indicator=True)\n",
    "\n",
    "msgs_wrole_id.shape\n",
    "\n",
    "msgs_wrole_id._merge.value_counts()\n",
    "\n",
    "\n",
    "msgs_wrole_id.drop(columns = ['_merge'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs_wrole_id[msgs_wrole_id.date_dt != msgs_wrole_id.date_dt_corrected]\\\n",
    "[['date', 'time', 'date_dt', 'date_dt_corrected', 'file_source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns do we need to fix?\n",
    "msgs_wrole_id.columns[msgs_wrole_id.columns.str.startswith('date')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs_wrole_id['date_dt'] = msgs_wrole_id['date_dt_corrected']\n",
    "\n",
    "msgs_wrole_id['date_time'] = \\\n",
    " pd.to_datetime(msgs_wrole_id['date_dt_corrected'].astype(str) + ' ' + msgs_wrole_id.time.astype(str))\n",
    "\n",
    "# round to minutes for goruping\n",
    "msgs_wrole_id['date_time_minutes'] = msgs_wrole_id.date_time.dt.floor('Min')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# In Script 5, we create ids with a \"group\", including date_time_minutes\n",
    "# We're fixing that here based on the corrected datetime format, but this should not have\n",
    "# an impact on the translations done in Script 7 (a standalone ID was created in that one)\n",
    "# We don't use it, so we'll just remove them here\n",
    "\n",
    "# We need to recreate this, based on grouping b\n",
    "to_drop = msgs_wrole_id.columns[msgs_wrole_id.columns.str.contains('_wgroup')].to_list()\n",
    "\n",
    "msgs_wrole_id.drop(columns = to_drop, inplace = True)\n",
    "\n",
    "msgs_wrole_id.columns[msgs_wrole_id.columns.str.contains('_wgroup')].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Manually correct incorrect translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_correction = msgs_wrole_id.loc[(msgs_wrole_id.content_w_translation == 'Greasy') |\n",
    "                                      (msgs_wrole_id.content == 'Grasias')]['id'].to_list()\n",
    "len(manual_correction)\n",
    "\n",
    "msgs_wrole_id[(msgs_wrole_id.id.isin(manual_correction))][['content','content_w_translation',\n",
    "                                                           'detectedSourceLanguage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs_wrole_id['content_w_translation'] = np.where(msgs_wrole_id.id.isin(manual_correction), \n",
    "                                                  'Thank you', \n",
    "                                                  msgs_wrole_id.content_w_translation)\n",
    "\n",
    "msgs_wrole_id[(msgs_wrole_id.id.isin(manual_correction))]\\\n",
    "[['content','content_w_translation','detectedSourceLanguage']].sample(n = 10)\n",
    "\n",
    "\n",
    "# Check that others haven't been messed up\n",
    "msgs_wrole_id[~(msgs_wrole_id.id.isin(manual_correction))]\\\n",
    "[['content','content_w_translation','detectedSourceLanguage']].sample(n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create a replied to column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort messages by text chain and date/time\n",
    "msgs_sorted = msgs_wrole_id.sort_values(by = ['StudentID', 'text_chain_ids', 'date_time'])\\\n",
    "              .reset_index(drop = True)\n",
    "\n",
    "# Created lagged msg columns\n",
    "msgs_sorted[['replied_to_content', 'replied_to_msg_id', 'replied_to_msg_date_time']] = \\\n",
    "    msgs_sorted.groupby('text_chain_ids')[['content_w_translation', 'id', 'date_time']]\\\n",
    "    .shift(+1)\n",
    "\n",
    "msgs_sorted['time_diff'] = msgs_sorted.date_time - msgs_sorted.replied_to_msg_date_time\n",
    "\n",
    "#msgs_sorted_content_only = msgs_sorted[['text_chain_ids', 'sender_role_id', 'receiver_role_id', \n",
    "#                                        'date_time', 'id', 'content_w_translation', 'broad_type']]\\\n",
    "#                          .drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_cols_to_view = ['text_chain_ids', 'sender_role_id', 'receiver_role_id', \n",
    "                         'date','date_time', 'id', 'content_w_translation',\n",
    "                         'replied_to_content', 'replied_to_msg_id', 'replied_to_msg_date_time', 'time_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = msgs_sorted.text_chain_ids.drop_duplicates().sample(n=1, random_state = 35).values \n",
    "msgs_sorted[msgs_sorted.text_chain_ids == sample[0]][relevant_cols_to_view]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = msgs_sorted.text_chain_ids.drop_duplicates().sample(n=1, random_state = 89).values\n",
    "\n",
    "pd.set_option('display.max_rows', msgs_sorted.shape[0]+1)\n",
    "msgs_sorted[msgs_sorted.text_chain_ids == sample[0]][relevant_cols_to_view]\n",
    "\n",
    "#'teacher_id_4:parent_id_2035'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_msg_in_chain = msgs_sorted.groupby('text_chain_ids')[['id']].first()\\\n",
    "                    .reset_index()\\\n",
    "                    .rename(columns = {'id':'root_id'})\n",
    "\n",
    "msgs_sorted_w_root = pd.merge(msgs_sorted, \n",
    "                              first_msg_in_chain, \n",
    "                              how = 'left', \n",
    "                              on = 'text_chain_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msgs_sorted_w_root.head()\n",
    "# check to see this looks right\n",
    "msgs_sorted_w_root[msgs_sorted_w_root.text_chain_ids == sample[0]][relevant_cols_to_view + ['root_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs_sorted_w_root['replied_to_msg_id'] = np.where(msgs_sorted_w_root.replied_to_msg_id.isna(),\n",
    "                                                  None,  \n",
    "                                                  msgs_sorted_w_root.replied_to_msg_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs_sorted_w_root.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one last date check \n",
    "pd.merge(msgs_sorted_w_root.groupby('school_merge')[['date_dt']].min().reset_index(),\n",
    "         msgs_sorted_w_root.groupby('school_merge')[['date_dt']].max().reset_index(),\n",
    "         how = 'inner', on = 'school_merge')\\\n",
    ".rename(columns = {'date_dt_x': 'min_date',\n",
    "                   'date_dt_y': 'max_date'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Write as pickle for use in Script #09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todaysdate = date.today().strftime(\"%m%d%Y\")\n",
    "todaysdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_filename = '../data/analysis_data/translated_msgs_wrole_ids_' + todaysdate + '.pkl'\n",
    "write_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs_sorted_w_root.to_pickle(write_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add all content columns for cleaning (strip escape chars)\n",
    "content_columns = msgs_sorted_w_root.columns[msgs_sorted_w_root.columns.str.startswith('content')].to_list()\n",
    "content_columns.remove('content_len')\n",
    "content_columns.extend(['replied_to_content', 'translatedText', 'translatedText_rm_html'])\n",
    "\n",
    "content_columns\n",
    "\n",
    "# replace\n",
    "for col in content_columns:\n",
    "    msgs_sorted_w_root[col] = msgs_sorted_w_root[col].str.replace('\\r|\\n', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Clean and write as csv for use in conference analyses (Scripts #10+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todaysdate = date.today().strftime(\"%m%d%Y\")\n",
    "write_filename = '../data/analysis_data/translated_msgs_wrole_ids_' + todaysdate + '.csv' \n",
    "write_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write as csv for R script\n",
    "msgs_sorted_w_root.to_csv(write_filename, index = False)\n",
    "\n",
    "# Check same N rows\n",
    "msg_data_check = pd.read_csv(write_filename)\n",
    "msg_data_check.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
