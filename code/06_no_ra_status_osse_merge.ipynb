{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data visualization\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import os\n",
    "from functools import reduce\n",
    "from collections import OrderedDict \n",
    "\n",
    "control_color = \"#444444\"\n",
    "treatment_color = \"#2B4888\"\n",
    "\n",
    "## cleaner school names\n",
    "schoolmap_msg = {'Anacostia HS': \"Anacostia\", \n",
    "                 'Columbia Heights EC (CHEC)': \"CHEC\",\n",
    "                 'Dunbar HS': 'Dunbar'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load messaging data from script 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_data = pd.read_pickle('../data/analysis_data/full_year_msg_data_pickle.pkl')\n",
    "msg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('N messages by school:')\n",
    "pd.merge(msg_data.school_merge.value_counts().reset_index(),\n",
    "         msg_data.school_merge.value_counts(normalize = True).reset_index(), \n",
    "         on = 'index').rename(columns = {'index': 'school_name',\n",
    "                                         'school_merge_x': 'counts',\n",
    "                                         'school_merge_y':'pct'})\n",
    "\n",
    "print('N students per school:')\n",
    "msg_data[['school_merge','StudentID']].drop_duplicates().groupby('school_merge').count()\\\n",
    ".reset_index().rename(columns = {'StudentID': 'count_unique_students'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load and prep OSSE data pulled from Qlik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# osse ids for all 6 schools\n",
    "osse_ids = pd.read_csv(\"../data/analysis_data/osse_data_formatching_withdem_all6_qlik.csv\")\n",
    "\n",
    "#osse_ids_SY1920.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osse_ids['osse_school_merge'] = np.where(osse_ids.school_name.str.contains(\"Columbia Heights\"),\n",
    "                                'CHEC',\n",
    "                           np.where(osse_ids.school_name.str.contains(\"Anacostia\"),\n",
    "                                'Anacostia', \n",
    "                           np.where(osse_ids.school_name.str.contains(\"Dunbar\"),\n",
    "                                 'Dunbar',\n",
    "                           np.where(osse_ids.school_name.str.contains(\"Paul\"),\n",
    "                                 'Paul',\n",
    "                           np.where(osse_ids.school_name.str.contains(\"Friendship\"),\n",
    "                                 'Friendship',\n",
    "                           'Johnson'))))) \n",
    "\n",
    "osse_ids[['school_name', 'osse_school_merge']].drop_duplicates()\n",
    "\n",
    "# Rename columns so we don't get duplicates leading to _x, _y on merge\n",
    "osse_ids.rename(columns = {'school_name': 'osse_school_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset demographics to more recent SY (might use older SY if missing in recent one)\n",
    "osse_ids_SY1920 = osse_ids[osse_ids.school_year == \"SY1920\"].copy()\n",
    "osse_ids_SY1819 = osse_ids[osse_ids.school_year == \"SY1819\"].copy()\n",
    "\n",
    "osse_ids_SY1920.shape\n",
    "osse_ids_SY1819.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Merge message data to OSSE data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Merge to SY1920 OSSE data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all messages to the osse info for SY1920\n",
    "\n",
    "osse_msg_merge_1920 = pd.merge(msg_data, \n",
    "                                    osse_ids_SY1920, \n",
    "                                    how = 'left', \n",
    "                                    left_on = ['school_merge', 'StudentID'], \n",
    "                                    right_on = ['osse_school_merge', 'lea_student_id'], \n",
    "                                    indicator = 'found_osse1920')\n",
    "\n",
    "\n",
    "#osse_msg_merge_1920.head()\n",
    "\n",
    "osse_msg_merge_1920.found_osse1920.value_counts()\n",
    "osse_msg_merge_1920.found_osse1920.value_counts(normalize = True)\n",
    "\n",
    "\n",
    "osse_msg_merge_1920['source_of_match'] = np.where(osse_msg_merge_1920.found_osse1920 == 'both', \n",
    "                                                  'osse_sy1920', \n",
    "                                                  'unmatched')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. For those that did not get a match for in the first round of matching to SY1920 data, merge to SY1819 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to match the remaining one not found in OSSE SY19-20 to SY18-19\n",
    "left_only = osse_msg_merge_1920[osse_msg_merge_1920.found_osse1920 == 'left_only'].copy()\n",
    "\n",
    "# keep only columns used in the orignal msg data to avoid duplicate columns\n",
    "msg_data_columns = list(msg_data.columns)\n",
    "left_only[msg_data_columns].shape\n",
    "\n",
    "remain_schools_osse_merge = pd.merge(left_only[msg_data_columns],\n",
    "                                     osse_ids_SY1819, \n",
    "                                     how = 'left', \n",
    "                                     left_on = ['school_merge', 'StudentID'], \n",
    "                                     right_on = ['osse_school_merge', 'lea_student_id'], \n",
    "                                     indicator = 'found_osse1819')\n",
    "\n",
    "remain_schools_osse_merge['source_of_match'] = np.where(remain_schools_osse_merge.found_osse1819 == 'both', \n",
    "                                                        'osse_sy1819', \n",
    "                                                        'unmatched')\n",
    "remain_schools_osse_merge.found_osse1819.value_counts()\n",
    "remain_schools_osse_merge.found_osse1819.value_counts(normalize = True)\n",
    "\n",
    "remain_schools_osse_merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Concat the matches together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osse_merge_6_schools = pd.concat([osse_msg_merge_1920[osse_msg_merge_1920.source_of_match == 'osse_sy1920']\\\n",
    "                                  .drop(columns='found_osse1920'), \n",
    "                                 remain_schools_osse_merge.drop(columns='found_osse1819')])\n",
    "osse_merge_6_schools.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns that are leading to duplicates \n",
    "# 'student_tokens' only bc you can't dedupe with a list in a column\n",
    "osse_merge_6_schools.drop(columns = ['enrollment_date', \n",
    "                                     'withdrawal_date', \n",
    "                                     'student_tokens'], inplace = True)\n",
    "\n",
    "osse_merge_6_schools.drop_duplicates(inplace = True)\n",
    "\n",
    "# Compare df with dems and orig msg\n",
    "osse_merge_6_schools.shape\n",
    "msg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"N dupes:\", osse_merge_6_schools.id.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osse_merge_6_schools.source_of_match.value_counts()\n",
    "osse_merge_6_schools.source_of_match.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Sanity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Randomly sample merges from the second semester schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_sem_schools = ['Paul', 'Friendship', 'Johnson']\n",
    "\n",
    "second_sem_merge = osse_merge_6_schools[osse_merge_6_schools.osse_school_merge.isin(second_sem_schools)].copy()\n",
    "second_sem_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like the merge actually worked\n",
    "\n",
    "#second_sem_merge[['school_merge', 'StudentID', 'student_name', 'lea_student_id', 'first_name', 'last_name',\n",
    "#                 'osse_school_name']].drop_duplicates().sample(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Check the unmatched ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched = osse_merge_6_schools[osse_merge_6_schools.source_of_match == 'unmatched'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_unmatched_names = unmatched[['school_merge', 'student_name', 'StudentID']].drop_duplicates()\n",
    "\n",
    "osse_ids[osse_ids.lea_student_id.isin(unique_unmatched_names.StudentID)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0. Write files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osse_merge_6_schools.to_pickle('../data/analysis_data/messages_w_demographics_osse6_schools_pickle.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you're running in R\n",
    "msgs_to_modify = osse_merge_6_schools.copy()\n",
    "\n",
    "msgs_to_modify['content'] = msgs_to_modify['content'].str.replace('\\r', '')\n",
    "msgs_to_modify['content_upper'] = msgs_to_modify['content_upper'].str.replace('\\r', '')\n",
    "\n",
    "\n",
    "msgs_to_modify.shape\n",
    "msgs_to_modify.to_csv('../data/analysis_data/messages_w_demographics_osse6_schools_csv.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_csv('../data/analysis_data/messages_w_demographics_osse6_schools_csv.csv')\n",
    "check.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
